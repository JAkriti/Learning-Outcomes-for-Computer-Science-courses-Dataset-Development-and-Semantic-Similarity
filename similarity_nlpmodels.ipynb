{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOa7efqmkMICRJBh+kCU602",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAkriti/Learning-Outcomes-for-Computer-Science-courses-Dataset-Development-and-Semantic-Similarity/blob/main/similarity_nlpmodels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTneOBThyhM-"
      },
      "source": [
        "# **Installing Transformers**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentence_transformers openai"
      ],
      "metadata": {
        "id": "4Z7Gc0Flv_rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVRTtHheygig"
      },
      "source": [
        "# **Similarity Scores**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlbertConfig, AlbertModel, AlbertTokenizer, AlbertForPreTraining\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, util, models\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "data=pd.read_excel(open('Dataset_LOs.xlsx', 'rb'),\n",
        "              sheet_name='Algorithm Analysis and Design')\n",
        "data1 = pd.DataFrame()\n",
        "###############################################################################\n",
        "def albert(a,b):\n",
        "    model = SentenceTransformer('paraphrase-albert-small-v2')\n",
        "    emb1 = model.encode(a.dropna())\n",
        "    emb2 = model.encode(b.dropna())\n",
        "    count = 0\n",
        "    count1 = 0\n",
        "    average_1 = []\n",
        "    for item in emb1:\n",
        "        count = count + 1\n",
        "        count1 = 0\n",
        "        sim = []\n",
        "        for item1 in emb2:\n",
        "              value = util.cos_sim(item, item1)\n",
        "              value_1 = value.detach().numpy()\n",
        "              value_1 = value_1.squeeze()\n",
        "              sim.append(value_1) \n",
        "        values = np.array(sim)  \n",
        "        average = np.mean(values)    \n",
        "    average_1.append(average)\n",
        "    values_avg = np.array(sim)\n",
        "    avg_val = np.mean(values_avg)\n",
        "    return avg_val\n",
        "################################################################################\n",
        "def distil(a,b):\n",
        "    model = SentenceTransformer('all-distilroberta-v1')\n",
        "    emb1 = model.encode(a.dropna())\n",
        "    emb2 = model.encode(b.dropna())\n",
        "    count = 0\n",
        "    count1 = 0\n",
        "    average_1 = []\n",
        "    for item in emb1:\n",
        "        count = count + 1\n",
        "        count1 = 0\n",
        "        sim = []\n",
        "        for item1 in emb2:\n",
        "              value = util.cos_sim(item, item1)\n",
        "              value_1 = value.detach().numpy()\n",
        "              value_1 = value_1.squeeze()\n",
        "              sim.append(value_1)\n",
        "        values = np.array(sim)  \n",
        "        average = np.mean(values)    \n",
        "    average_1.append(average)\n",
        "    values_avg = np.array(sim)\n",
        "    avg_val = np.mean(values_avg)\n",
        "    return avg_val\n",
        "################################################################################\n",
        "def bert(a,b):\n",
        "    model = SentenceTransformer('multi-qa-distilbert-cos-v1')\n",
        "    emb1 = model.encode(a.dropna())\n",
        "    emb2 = model.encode(b.dropna())\n",
        "    count = 0\n",
        "    count1 = 0\n",
        "    average_1 = []\n",
        "    for item in emb1:\n",
        "        count = count + 1\n",
        "        count1 = 0\n",
        "        sim = []\n",
        "        for item1 in emb2:\n",
        "              value = util.cos_sim(item, item1)\n",
        "              value_1 = value.detach().numpy()\n",
        "              value_1 = value_1.squeeze()\n",
        "              sim.append(value_1) \n",
        "        values = np.array(sim)  \n",
        "        average = np.mean(values)    \n",
        "    average_1.append(average)\n",
        "    values_avg = np.array(sim)\n",
        "    avg_val = np.mean(values_avg)\n",
        "    return avg_val\n",
        "################################################################################\n",
        "def mpnetv1(a,b):\n",
        "    model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')\n",
        "    emb1 = model.encode(a.dropna())\n",
        "    emb2 = model.encode(b.dropna())\n",
        "    count = 0\n",
        "    count1 = 0\n",
        "    average_1 = []\n",
        "    for item in emb1:\n",
        "        count = count + 1\n",
        "        count1 = 0\n",
        "        sim = []\n",
        "        for item1 in emb2:\n",
        "              value = util.cos_sim(item, item1)\n",
        "              value_1 = value.detach().numpy()\n",
        "              value_1 = value_1.squeeze()\n",
        "              sim.append(value_1)\n",
        "        values = np.array(sim)  \n",
        "        average = np.mean(values)    \n",
        "    average_1.append(average)\n",
        "    values_avg = np.array(sim)\n",
        "    avg_val = np.mean(values_avg)\n",
        "    return avg_val\n",
        "################################################################################\n",
        "def minilm(a,b):\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    emb1 = model.encode(a.dropna())\n",
        "    emb2 = model.encode(b.dropna())\n",
        "    count = 0\n",
        "    count1 = 0\n",
        "    average_1 = []\n",
        "    for item in emb1:\n",
        "        count = count + 1\n",
        "        count1 = 0\n",
        "        sim = []\n",
        "        for item1 in emb2:\n",
        "              value = util.cos_sim(item, item1)\n",
        "              value_1 = value.detach().numpy()\n",
        "              value_1 = value_1.squeeze()\n",
        "              sim.append(value_1) \n",
        "        values = np.array(sim)  \n",
        "        average = np.mean(values)    \n",
        "    average_1.append(average)\n",
        "    values_avg = np.array(sim)\n",
        "    avg_val = np.mean(values_avg)\n",
        "    return avg_val\n",
        "################################################################################\n",
        "def mpnet(a,b):\n",
        "    model = SentenceTransformer('all-mpnet-base-v2')\n",
        "    emb1 = model.encode(a.dropna())\n",
        "    emb2 = model.encode(b.dropna())\n",
        "    count = 0\n",
        "    count1 = 0\n",
        "    average_1 = []\n",
        "    for item in emb1:\n",
        "        count = count + 1\n",
        "        count1 = 0\n",
        "        sim = []\n",
        "        for item1 in emb2:\n",
        "              value = util.cos_sim(item, item1)\n",
        "              value_1 = value.detach().numpy()\n",
        "              value_1 = value_1.squeeze()\n",
        "              sim.append(value_1) \n",
        "        values = np.array(sim)  \n",
        "        average = np.mean(values)    \n",
        "    average_1.append(average)\n",
        "    values_avg = np.array(sim)\n",
        "    avg_val = np.mean(values_avg)\n",
        "    return avg_val\n",
        "################################################################################\n",
        "def ada(a,b):\n",
        "    model = \"text-embedding-ada-002\"\n",
        "    count = 0\n",
        "    count1 = 0\n",
        "    average_1 = []\n",
        "    for item in a:\n",
        "        emb11 = openai.Embedding.create(input=item, engine=model)['data'][0]['embedding']\n",
        "        count = count + 1\n",
        "        count1 = 0\n",
        "        sim = []\n",
        "        for item1 in b:\n",
        "              emb22 = openai.Embedding.create(input=item1, engine=model)['data'][0]['embedding']\n",
        "              value_1 = np.dot(emb11, emb22) / (np.sqrt(np.dot(emb11,emb11)) * np.sqrt(np.dot(emb22,emb22)))\n",
        "              # value_1 = value.detach().numpy()\n",
        "              # value_1 = value_1.squeeze()\n",
        "              sim.append(value_1) \n",
        "        values = np.array(sim)  \n",
        "        average = np.mean(values)    \n",
        "    average_1.append(average)\n",
        "    values_avg = np.array(sim)\n",
        "    avg_val = np.mean(values_avg)\n",
        "    return avg_val\n",
        "################################################################################\n",
        "def davinci(a,b):\n",
        "    model = \"text-similarity-davinci-001\"\n",
        "    count = 0\n",
        "    count1 = 0\n",
        "    average_1 = []\n",
        "    for item in a:\n",
        "        emb11 = openai.Embedding.create(input=item, engine=model)['data'][0]['embedding']\n",
        "        count = count + 1\n",
        "        count1 = 0\n",
        "        sim = []\n",
        "        for item1 in b:\n",
        "              emb22 = openai.Embedding.create(input=item1, engine=model)['data'][0]['embedding']\n",
        "              value_1 = np.dot(emb11, emb22) / (np.sqrt(np.dot(emb11,emb11)) * np.sqrt(np.dot(emb22,emb22)))\n",
        "              # value_1 = value.detach().numpy()\n",
        "              # value_1 = value_1.squeeze()\n",
        "              sim.append(value_1) \n",
        "        values = np.array(sim)  \n",
        "        average = np.mean(values)    \n",
        "    average_1.append(average)\n",
        "    values_avg = np.array(sim)\n",
        "    avg_val = np.mean(values_avg)\n",
        "    return avg_val\n",
        "################################################################################\n",
        "df1 = pd.DataFrame(columns=['University 1', 'University 2', 'ALBERT'])\n",
        "counter = 0\n",
        "for i in range(0,len(data.columns)):\n",
        "  df = data.iloc[:, i].replace('', np.nan)\n",
        "  a = df.dropna()\n",
        "  for j in range(0,len(data.columns)):\n",
        "    if i != j:\n",
        "      df = data.iloc[:, j].replace('', np.nan)\n",
        "      b = df.dropna()\n",
        "      values_albert =  albert(a,b)\n",
        "      values_distil = distil(a,b)\n",
        "      values_bert = bert(a,b)\n",
        "      values_mpnetv1 = mpnetv1(a,b)\n",
        "      values_minilm = minilm(a,b)\n",
        "      values_mpnet = mpnet(a,b)\n",
        "      values_davinci = davinci(a,b)\n",
        "      values_ada = ada(a,b)\n",
        "      row1 = {'University 1': data.columns[i], 'University 2': data.columns[j], 'ALBERT':values_albert, 'DistilRoberta':values_distil, 'DistilBERT':values_bert, 'MPNeTv1':values_mpnetv1, 'MiniLM':values_minilm, 'MPNeTv2':values_mpnet, 'Davinci':values_davinci, 'ada':values_ada}\n",
        "      df1 = df1.append(row1,ignore_index=True) \n",
        "print(df1)\n",
        "df1.to_csv('Algorithms.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "dQe9hx9z8ydj",
        "outputId": "0b7600a0-c782-4c4c-86cb-aecefe30019d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-892e62bde46b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlbertConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAlbertModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAlbertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAlbertForPreTraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating University Pair names with abbreviations"
      ],
      "metadata": {
        "id": "fI3ORYM33RC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "data=pd.read_excel(open('Dataset_LOs.xlsx', 'rb'),\n",
        "              sheet_name='AbbProgramming')\n",
        "df_a = pd.DataFrame()\n",
        "for i in range(0,len(data.columns)):\n",
        "  for j in range(0,len(data.columns)):\n",
        "    if i != j:\n",
        "      row1 = {'University 1': data.columns[i], 'University 2': data.columns[j]}\n",
        "      df_a = df_a.append(row1,ignore_index=True)\n",
        "df_a[\"Pairs\"] = df_a['University 1'] +\"-\"+ df_a['University 2']\n",
        "df1 = pd.read_csv('Software.csv')\n",
        "df1[\"Pairs\"] = df_a[\"Pairs\"]\n",
        "df1.to_csv('Programming.csv')"
      ],
      "metadata": {
        "id": "yVMk7x3Y3hEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecting 10 university pairs starting with most similar in each model"
      ],
      "metadata": {
        "id": "lGbmDpqC4LUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "df1 = pd.read_csv('Algorithms.csv')\n",
        "df1[\"Names\"] = df1['University 1'] +\"-\"+ df1['University 2']\n",
        "count = 0\n",
        "################################################################################\n",
        "n = 10\n",
        "while count < 10:\n",
        "  n = n + 1\n",
        "  ALBERT = df1['ALBERT']\n",
        "  df2 = df1.sort_values(by=['ALBERT'], ascending=False)\n",
        "  list1 = df2.head(n)\n",
        "  BERT = df1['DistilBERT']\n",
        "  df3 = df1.sort_values(by=['DistilBERT'], ascending=False)\n",
        "  list2 = df3.head(n)\n",
        "  DistilRoberta = df1['DistilRoberta']\n",
        "  df4 = df1.sort_values(by=['DistilRoberta'], ascending=False)\n",
        "  list3 = df4.head(n)\n",
        "  MPNet = df1['MPNeTv1']\n",
        "  df5 = df1.sort_values(by=['MPNeTv1'], ascending=False)\n",
        "  list4 = df5.head(n)\n",
        "  RoBERTa_base = df1['MPNeTv2']\n",
        "  df6 = df1.sort_values(by=['MPNeTv2'], ascending=False)\n",
        "  list5 = df6.head(n)\n",
        "  RoBERTa_large = df1['MiniLM']\n",
        "  df7 = df1.sort_values(by=['MiniLM'], ascending=False)\n",
        "  list6 = df7.head(n)\n",
        "  df8 = df1.sort_values(by=['Davinci'], ascending=False)\n",
        "  list7 = df8.head(n)\n",
        "  df9 = df1.sort_values(by=['ada'], ascending=False)\n",
        "  list8 = df9.head(n)\n",
        "  intdf=list(set(list1.Pairs) & set(list2.Pairs) & set(list3.Pairs)& set(list4.Pairs)& set(list5.Pairs)& set(list6.Pairs)& set(list7.Pairs)& set(list8.Pairs))\n",
        "  count = len(intdf)\n",
        "  # print(count,n)\n",
        "df_new = pd.DataFrame()\n",
        "for i in range(0,len(intdf)):\n",
        "  df_new = df_new.append(df1.loc[df1['Pairs'] == intdf[i]])\n",
        "df2 = pd.DataFrame().assign(University=df_new['Pairs'],ALBERT=df_new['ALBERT'], DistilBERT=df_new['DistilBERT'], DistilRoBERTa = df_new['DistilRoberta'], MPNeTv1 = df_new['MPNeTv1'], MPNeTv2 = df_new['MPNeTv2'], MiniLM = df_new['MiniLM'], Davinci = df_new['Davinci'], ada = df_new['ada'], index=True)\n",
        "ax = df2.plot(x='University', kind='bar', stacked=True, colormap=plt.cm.Pastel1)\n",
        "for p in ax.patches:\n",
        "    width, height = round(p.get_width(),2), round(p.get_height(),2)\n",
        "    x, y = p.get_xy() \n",
        "    ax.text(x+width/2, \n",
        "            y+height/2, \n",
        "            '{:.2f}'.format(height), \n",
        "            horizontalalignment='center', \n",
        "            verticalalignment='center',size=7)\n",
        "plt.ylim([0,8])\n",
        "plt.xticks(rotation = 25)\n",
        "plt.xticks(fontsize = 7)\n",
        "plt.yticks(fontsize = 8)\n",
        "ax.set_ylabel('Similarity Score')\n",
        "ax.set_xlabel('University')\n",
        "plt.legend(loc='upper left', fontsize=8,bbox_to_anchor=(0, 1),ncol=3, fancybox=True)\n",
        "plt.savefig(\"Programming.pdf\", format=\"pdf\", bbox_inches='tight')"
      ],
      "metadata": {
        "id": "5zvSD5MU4Urf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}